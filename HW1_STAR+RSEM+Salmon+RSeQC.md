---
title: "Bioinformatics 2022 HW_1"
author: "your name"
date: "Date"
output: html_document

---

```r
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 1: STAR alignment

We will give you a simple example to test high throughput sequencing alignment for RNA-seq data. Normally for paired-end sequencing data, each sample will have two separate FASTQ files, with line-by-line correspondence to the two reads from the same fragment. Read mapping could take a long time, so we have created just two FASTQ files of one RNA-seq sample with only 30,000 fragments (2 * 30,000 reads) for you to run STAR instead of the full data. The files are located on Huawei Cloud at /mnt/data/data/HW1/raw_data1. The mapping will generate one single output file. 
**Use STAR (Dobin et al, Bioinformatics 2012) to map the reads to the reference genome, available on Huawei Cloud at /mnt/data/data/HW1/index/star_hg38_index. Use the paired-end alignment mode and generate the output in SAM format. Please include full STAR report.How many reads are mappable and how many are uniquely mappable?**

```
Sequencing data:
/mnt/data/data/HW1/raw_data1
module: STAR_2.7.10a
index: /mnt/data/data/HW1/index/star_hg38_index
```

```shell
# 下载基因组注释文件GRCh38.fa
wget -P ./genome https://ftp.ensembl.org/pub/release-106/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz --no-check-certificate

#!/bin/bash
# Build the STAR index
#--1--# 构建基因组索引,在这里已经构建好了索引
STAR --runThreadN 10 \
     --runMode genomeGenerate \
     --genomeDir ./index/star_hg38_index \
     --genomeFastaFiles ./genome/hg38/Homo_sapiens.GRCh38.dna.primary_assembly.fa \
     --sjdbGTFfile ./genome/hg38/genes.gtf \
     --sjdbOverhang 75

# --runThreadN：线程数。
# --runMode genomeGenerate：构建基因组索引。
# --genomeDir：索引目录。（index_dir一定要是存在的文件夹，需提前建好）
# --genomeFastaFiles：基因组文件。
# --sjdbGTFfile：基因组注释文件。
# --sjdbOverhang：reads长度减1。
# 索引构建完成后，就可以看到index_dir中生成了以下文件：chrLength.txt  chrNameLength.txt  chrName.txt  chrStart.txt  exonGeTrInfo.tab  exonInfo.tab  geneInfo.tab  Genome  genomeParameters.txt  Log.out  SA  SAindex  sjdbInfo.txt  sjdbList.fromGTF.out.tab  sjdbList.out.tab  transcriptInfo.tab

#--2--# 进行 reads 比对
STAR --twopassMode Basic  \
     --genomeDir ./index/star_hg38_index \
     --readFilesIn ./raw_data1/subA_l.fastq  ./raw_data1/subA_r.fastq  \
     --outSAMtype SAM \
     --runThreadN 8 \
     --outFileNamePrefix subA_res

# --twopassMode Basic：使用two-pass模式进行reads比对。简单来说就是先按索引进行第一次比对，而后把第一次比对发现的新剪切位点信息加入到索引中进行第二次比对。
# --quantMode TranscriptomeSAM GeneCounts：将reads比对至转录本序列。
# --runThreadN：线程数。
# --genomeDir：索引目录。
# --alignIntronMin：最短的内含子长度。（根据GTF文件计算）
# --alignIntronMax：最长的内含子长度。（根据GTF文件计算）
# --outSAMtype BAM SortedByCoordinate：输出BAM文件并进行排序。
# --sjdbOverhang：reads长度减1。
# --outSAMattrRGline：ID代表样本ID，SM代表样本名称，PL为测序平台。在使用GATK进行SNP Calling时同一SM的样本可以合并在一起。
# --outFilterMismatchNmax：比对时允许的最大错配数。
# --outSJfilterReads Unique：对于跨越剪切位点的reads（junction reads)，只考虑跨越唯一剪切位点的reads。
# --outSAMmultNmax：每条reads输出比对结果的数量。
# --outFileNamePrefix：输出文件前缀。
# --outSAMmapqUnique 60：将uniquely mapping reads的MAPQ值调整为60，满足下游使用GATK进行分析的需要。
# --readFilesCommand：对FASTQ文件进行操作。
# --readFilesIn：输入FASTQ文件的路径。比对完成后，我们可以看到输出目录下有以下文件：

# "Log.final.out"里记录了许多比对情况的统计信息

# How many reads are mappable and how many are uniquely mappable
grep "Number of input reads" subA_resLog.final.out | awk '{print $NF}'  # 29988
grep "Uniquely mapped reads number" subA_resLog.final.out | awk '{print $NF}' # 19290
```

![](D:\software\MarkText\picture\2023-11-17-18-18-22-image.png)

```
**Answer:** The output files of STAR mapping are shown 
above. The “.final.out” file contains the summary of mapping results. As
 we can see from the figure below, there are 19,293 uniquely mapped 
reads, 8,901 reads mapped to multiple loci and 79 reads mapped to too 
many loci. **Therefore, 28,273 reads, which is 94.28% are 
mappable. 19,293 reads, which is 64.35% is uniquely mappable. The 
mapping process takes about 11 seconds**
```

### Problem 2: RNA-seq quality control

You are asked by a collaborator to analyze four RNA-seq libraries. She suspects that the libraries are generally of high-quality but is concerned that a sample may have been switched with her benchmates during processing. To save time, we have provided four bam file generated by STAR in /mnt/data/data/HW1/raw_data2.  

Please use RSeQC (Liguo Wang et al, Bioinformatics 2012) geneBody_coverage.py and tin.py modules to determine whether any of the samples exhibit unusual quality control metrics. To expedite the process, you can use housekeeping genes as reference, which provided in /mnt/data/data/HW1/raw_data2. Overall, identify the best and worst libraries. Your answer should include screen shots and tables as necessary as if you were delivering a report to the collaborator.

```
data:
/mnt/data/data/HW1/raw_data2/bamFile
module:RSeQC v4.0.0
```

```shell
# #请使用 RSeQC 包 中 geneBody_coverage.py 和 tin.py 模块来确定是否有样本显示出异常的质量控制指标。
## 安装
pip install RSeQC

##准备输入文件：确保您准备了必要的输入文件，包括样本的BAM文件和housekeeping genes（参考基因）。将BAM文件放置在一个目录中，将housekeeping genes列表保存到一个文件中。
#--1--#运行geneBody_coverage.py：在命令行中运行geneBody_coverage.py模块以评估基因区域的reads覆盖情况.对于每个样本，重复此步骤.
geneBody_coverage.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_WAligned.sortedByCoord.out.bam -o geneBody_coverage_W.txt
geneBody_coverage.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_XAligned.sortedByCoord.out.bam -o geneBody_coverage_X.txt
geneBody_coverage.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_YAligned.sortedByCoord.out.bam -o geneBody_coverage_Y.txt
geneBody_coverage.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_ZAligned.sortedByCoord.out.bam -o geneBody_coverage_Z.txt

#查看比对片段的统计结果
bam_stat.py -i ./raw_data2/bamFile/res_WAligned.sortedByCoord.out.bam

#--2--#运行tin.py：在命令行中运行tin.py模块以计算TIN（Transcript Integrity Number）分数.对于每个样本，重复此步骤。
tin.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_WAligned.sortedByCoord.out.bam 
tin.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_XAligned.sortedByCoord.out.bam 
tin.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_YAligned.sortedByCoord.out.bam 
tin.py -r ./raw_data2/hg38.HouseKeepingGenes.nochr.bed -i ./raw_data2/bamFile/res_ZAligned.sortedByCoord.out.bam 

#为所有样本生成了基因区域覆盖度和TIN分数的输出文件，您可以分析结果以确定是否有样本显示出异常的质量控制指标。您可以检查每个样本的基因区域覆盖度图和TIN分数，评估它们的质量。
## 脚本文件coverage_bin.py
## Z样本有问题！！！
```

<img src="file:///D:/software/MarkText/picture/2023-11-17-18-06-11-image.png" title="" alt="" width="309"><img src="file:///D:/software/MarkText/picture/2023-11-17-18-06-32-image.png" title="" alt="" width="308">

<img title="" src="file:///D:/software/MarkText/picture/2023-11-17-18-07-04-image.png" alt="" width="310"><img src="file:///D:/software/MarkText/picture/2023-11-17-18-07-28-image.png" title="" alt="" width="313">

![](D:\software\MarkText\picture\2023-11-17-18-09-17-image.png)

![](D:\software\MarkText\picture\2023-11-17-18-08-52-image.png)

```python
# file: coverage_bin.py
#!/usr/bin/python
# vim: set fileencoding=<encoding name> :
# coding=utf-8

import matplotlib.pyplot as plt

# 读取基因区域覆盖度数据
coverage_file = 'geneBody_coverage_W.txt.geneBodyCoverage.txt'
gene_regions = []
coverage = []

with open(coverage_file, 'r') as file:
    for line in file:
        line = line.strip().split('\t')
        gene_regions.append(line[0])
        coverage.append(float(line[1]))

# 绘制基因区域覆盖度图
plt.figure(figsize=(10, 6))
plt.bar(gene_regions, coverage)
plt.xlabel('Sample')
plt.ylabel('Gene Coverage')
plt.title('Gene Body Coverage')
plt.xticks(rotation=45)
plt.show()

# 读取TIN分数数据
tin_file = 'res_WAligned.sortedByCoord.out.tin.xls'
samples = []
tin_scores = []

with open(tin_file, 'r') as file:
    for line in file:
        line = line.strip().split('\t')
        samples.append(line[0])
        tin_scores.append(float(line[1]))

# 绘制TIN分数图
plt.figure(figsize=(10, 6))
plt.bar(samples, tin_scores)
plt.xlabel('Sample')
plt.ylabel('TIN Score')
plt.title('TIN Scores')
plt.xticks(rotation=45)
plt.show()
```

### Problem 3: Python programming

**One output of RSeQC is called geneBodyCoverage.r which contains normalized reads mapped to each % of gene / transcript body. Suppose that we want to visualize all 4 samples together to quickly perform quality control. Write a python program to extract the values and name from each file. The same script should then draw the gene body coverage for all the samples (2 rows x 2 cols) in one figure. We provide an example with 3 x 2 samples in one figure. Please identify the worst sample by your result.**

```python
# 师姐答案
import re,os
import numpy as np
import matplotlib.pyplot as plt
import collections

#Initialize variables.
sample_dict = {}
sep = '.'

#Loop through each file, and pull the first 100 numbers as the coverage values. Input as dictionary.
for filename in os.listdir('/Users/shixiaoying/2021/hkr'):
  file = open(os.path.join('/Users/shixiaoying/2021/hkr', filename), 'r')
  file = file.read()
  numbers = re.findall(r"[-+]?\d*\.\d+|\d+", file)
  numarrays = np.array(numbers[0:100], dtype="double")
  samplename = filename.split(sep,1)[0]
  sample_dict.update({samplename : numarrays})

sample_dict=collections.OrderedDict(sorted(sample_dict.items()))

#Create subplot by parsing each dictionary entry and plot against an X vector.
x=range(0,100)
f, ax = plt.subplots(nrows=2,ncols=2, figsize=(15,10), sharex=True, sharey=True)
for a, (sample, coveragevalues) in zip(ax.flatten(), sample_dict.items()):
  a.plot(x, coveragevalues)
  a.set_title(sample)
  a.set_xlabel("Gene body percentile (5' -> 3')")
  a.set_ylabel("Coverage")

plt.tight_layout()
plt.show()
```

### Problem 4: RNA-seq quantification

Transcript quantification plays an important role in the analysis of RNA-seq data. A large number of tools have been developed to quantify expression at the transcript level. RSEM (Bo Li et al, BMC Bioinformatics 2011) is a software package for estimating gene and isoform expression levels from single-end or paired-end RNA-Seq data, it can perform the alignment step with three different aligners: bowtie, bowtie2, or STAR. Salmon (Rob Patro et al, Nature Methods 2017) is an ultra-fast alignment-free methods, which also can correct for GC-bias.
**Please run STAR+RSEM and Salmon on one good quality sample based on previous discussion to get FPKM and TPM. Identify the transcript and gene with the highest expression in this library from the Salmon output. **

```
data: /mnt/data/data/HW1/raw_data2/
module: STAR_2.7.10a, RSEM v1.3.3, Salmon 1.5.1
index: /mnt/data/data/HW1/index/salmon_hg38_index,/mnt/data/data/HW1/index/rsem_hg38_index/hg38
genome: /mnt/data/data/HW1/genome/hg38/genes.gtf
```

```shell
# your bash code here
#--1--#STAR 
STAR --genomeDir test/Liuxiaole_Training_homework_data/HW1/index/star_hg38_index/ \
     --readFilesIn test/Liuxiaole_Training_homework_data/HW1/raw_data2/fatstqFile/runY.fastq.gz \
     --readFilesCommand zcat --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM \
     --outFileNamePrefix test/Liuxiaole_Training_homework_data/HW1/raw_data2/output2/re
s_Y
#--2--#RSEM 定量
./RSEM-1.3.3/rsem-calculate-expression -no-bam-output --alignments -p 8 ./raw_data2/output2/res_YAligned.toTranscriptome.out.bam ./index/rsem_hg38_index/hg38 ./raw_data2/output2/RSEM_res_Y
# -p：线程数

#--3--#Salmon
# Salmon. index generation:
# salmon index -t ./genome/hg38/Homo_sapiens.GRCh38.dna.primary_assembly.fa -i ./index/homo38_index
#Salmon. quant
salmon quant -i test/Liuxiaole_Training_homework_data/HW1/index/salmon_hg38_index \
     -l A -r test/Liuxiaole_Training_homework_data/HW1/raw_data2/fatstqFile/runY.fastq.gz \
     -p 8 -o test/Liuxiaole_Training_homework_data/HW1/raw_data2/output2/salmon_Y
#Check the quant.sf file in the Salmon output directory. Identify the transcript with the highest TPM (Transcripts Per Million) value.
awk '{print $1, $4}' raw_data2/output2/salmon_Y/quant.sf | sort -k2,2nr |head -n 1
# MT 951751.897340

sort -k 4 -n raw_data2/output2/salmon_Y/quant.sf | tail -n 1
# MT      16569   16319.000       951751.897340   126335.845
```

![](D:\software\MarkText\picture\2023-11-17-18-32-59-image.png)

**Report the relative speed of STAR+RSEM and Salmon for the analyses of the sample. Comment on your results based on the lecture material.**

```r
#基因ID转换
library(biomaRt)
#选择人类数据集，建立数据库连接
mart <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
# 参考数据库以及版本list
listmart<-listDatasets(mart)

runY <- read.csv("/Users/shixiaoying/Downloads/salmon_quant/quant.sf",sep = "\t",row.names = 1)
# ID转换
annotLookup <- getBM(
    mart=mart,
    attributes=c("ensembl_transcript_id","ensembl_gene_id", "external_gene_name"),
    filter="ensembl_transcript_id",
    values=rownames(runY),
    uniqueRows=TRUE)
annotLookup[annotLookup$ensembl_transcript_id=='ENST00000361851',]
```

### Problem 5: Speed Comparison

**Report the relative speed of STAR+RSEM and Salmon for the analyses of the sample. Comment on your results based on the lecture material.**

```shell
# Report the relative speed of STAR+RSEM and Salmon for the analyses of the sample. Comment on your results based on the lecture material.
#--1--#salmon
tail -n 3 ./raw_data2/output2/salmon_Y_quant/aux_info/meta_info.json | head -n2
#    "start_time": "Sat Oct 14 21:25:39 2023",
#    "end_time": "Sat Oct 14 21:26:30 2023"

#--2--#STAR
 head -n 3 ./raw_data2/output2/res_YLog.final.out
                                 Started job on |       Oct 13 19:11:04
                             Started mapping on |       Oct 13 19:11:38
                                    Finished on |       Oct 13 19:13:56
#--3--#RSEM
# 当您运行 rsem-calculate-expression 命令时，程序会向终端输出有关计算进度和计算时间的信息。
查找计算时间戳:
计算时间通常以时间戳的形式呈现，显示了计算的开始和结束时间。例如：
>> begin_estimate expression at Sat Oct 16 12:34:56 2023.
>> finished estimate expression at Sat Oct 16 13:45:00 2023.

如果在终端输出中找不到计算时间的信息，您还可以检查 RSEM 运行的目录，查找是否有生成的日志文件(rsem.log)。这些日志文件中通常包含了有关计算时间的详细信息。
如果在终端输出中找不到计算时间的信息，建议检查 RSEM 运行的目录，查看是否生成了日志文件。您可以使用以下命令查看运行 RSEM 时指定的输出目录：
如果您在运行 rsem-calculate-expression 命令时指定了输出目录（例如 -p 8 --output-genome-bam input.bam reference output_directory），那么您可以在 output_directory 中寻找 rsem.log 文件或类似的日志文件。
在日志文件中，查找包含计算开始和结束时间的信息。如果找到相关的时间戳，您可以计算这两个时间戳之间的差异，以获取 RSEM 运行的总时间。
如果没有生成日志文件，您可以尝试重新运行 rsem-calculate-expression 命令，并确保在运行时指定一个输出目录，以便生成日志文件。



awk 'BEGIN{print("T1\tT2\tT3\tT4\tT5\tN1\tN2\tN3\tN4\tN5\n")}{print $4}' T1.sf T2.sf T3.sf T4.sf T5.sf N1.sf N2.sf N3.sf N4.sf N5.sf > salmon_result.txt
awk 'BEGIN {OFS="\t"} FNR==1 {print "Gene", FILENAME} {print $1, $5}' T1.sf T2.sf T3.sf T4.sf T5.sf N1.sf N2.sf N3.sf N4.sf N5.sf > merged_expression.tsv
```

### Problem 6:

**Plot the relationship between effective length, normalized read counts, TPM, and FPKM for this sample from the RSEM and Salmon output. Comment on the relative utility of each metric when analyzing gene expression data.**

```r
setwd("/home4/liuyw/test/Liuxiaole_Training_homework_data/HW1/raw_data2/output2")

library(ggplot2)
library(tidyverse)
library(ggcor)


rsem <- read.table("RSEM_res_Y.isoforms.results",sep="\t",header = T,fill = T)
salmon <- read.table("salmon_Y/quant.sf",sep="\t",header = T,fill = T)

str(rsem)
#计算相关性并返还p值，结果储存在列表中，请按自己需要进行保存
data.cor <- correlate(rsem[,4:7],
                      cor.test = TRUE, #进行相关性检验
                      method = "pearson", #检验方法，"pearson", "kendall", "spearman"
                      use = "everything", #缺失值处理方法
                      p.adjust = FALSE, #是否进行p值校正
                      p.adjust.method = "holm", #校正方法[不懂原理及应用的保存默认设置即可]，自定义请详细阅读说明及源码
) 

data.plot <- as_cor_tbl(data.cor, #相关性矩阵结果
                        show.diag = TRUE, #是否显示对角线
                        cluster = TRUE, #是否聚类
                        cluster.method = "complete" #聚类方法.....
) #转换为绘图格式


#绘制p5，新添加交叉标记、置信度星号、斜线纹理
mycolors <- c("#3b374c", "#44598e", "#64a0c0", "#7ec4b7", "#deebcd") #藏青-浅绿
quickcor(rsem[,4:7], 
         type = c("lower", "upper", "full")[3], #修改中括号内数值1~3选择不同类型的相关性矩阵
         cluster = T,  #是否进行聚类，默认值为False ，如果设置为T，那么就无法自定义顺序
         is.cor = F,  #输入的数据是否是相关性系数结果，默认为F，表示输入的是元素数据
         circular = F, #默认为F，表示是否转换为环形图，可设置为T
         grid.colour = "black", #网格颜色，默认为"grey50"
         grid.size = 0.25,  #网格线条粗细，默认0.25
         show.diag = T, #是否显示对角线
         cor.test = TRUE,
         method = "pearson") +

  #下面任选一个图形，其他的在代码最前面加#号，注意此处多了get_data(type = "lower")，可以设置"lower", "upper", "full"等
  geom_square(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2) +  #绘制正方形热图
  #geom_circle2(data = get_data(type = "lower"), colour = "grey35", size = 0.25, linetype = 2)+ #绘制圆形热图
  #geom_ellipse2(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2)+ #椭圆形热图
  #geom_colour(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2)+   #经典热图
  #geom_pie2(data = get_data(type = "lower"))+ #绘制饼图
  #geom_star(data = get_data(type = "lower"))+ #绘制五角星热图
  geom_shade(data = get_data(type = "lower"),sign = 1)+ #添加斜线阴影,sign>0,则在R值大于0的位置添加阴影。反之...
  geom_mark(data = get_data(type = "upper", r != 1, p.value < 0.05), #get_data调用dplyr包的filter函数用于过滤
            size = 2  #设置字体大小
            #aes(colour = r), #设置字体颜色映射
            #show.legend = F
  )+
  # geom_cross(data = get_data(type = "lower"), colour = "orange")+ #交叉标记，排除不显著的(即右上角空白处对应的位置)
  scale_fill_gradientn(colours = mycolors,  #自定义颜色
                       breaks = c(-1, 0, 1)) +  #自定义刻度值
  labs(fill = "Cor(R)")+ #修改图例标题
  theme(
    axis.text.x = element_text(color = c(rep(mycolors[1], 5), rep(mycolors[length(mycolors)-2], 6)), #X轴标签颜色
                               #face = "bold", 
                               size = 10), #设置加粗字体和大小
    axis.text.y = element_text(color = c(rep(mycolors[1], 6), rep(mycolors[length(mycolors)-2], 5)), #Y轴标签颜色
                               #face = "bold", 
                               size = 10)   #设置加粗字体和大小
  )

ggsave("RSEM_cor.pdf", width = 4.4, height = 4) #保存

#######-----------------------------------------------------------------------------
#Add FPKM calculation to the data frame. Use total # of mapped reads from the Salmon output log, 2.43M reads approx.
salmon$FPKM = (salmon$NumReads/sum(salmon$NumReads)/1000000)/(salmon$Length/1000)


data.cor <- correlate(salmon[,3:6],
                      cor.test = TRUE, #进行相关性检验
                      method = "pearson", #检验方法，"pearson", "kendall", "spearman"
                      use = "everything", #缺失值处理方法
                      p.adjust = FALSE, #是否进行p值校正
                      p.adjust.method = "holm", #校正方法[不懂原理及应用的保存默认设置即可]，自定义请详细阅读说明及源码
) 

data.plot <- as_cor_tbl(data.cor, #相关性矩阵结果
                        show.diag = TRUE, #是否显示对角线
                        cluster = TRUE, #是否聚类
                        cluster.method = "complete" #聚类方法.....
) #转换为绘图格式


#绘制p5，新添加交叉标记、置信度星号、斜线纹理
mycolors <- c("#1f294e","#5390b5","#eaebea","#d56e5e","#57121d") #经典红-蓝
quickcor(salmon[,3:6], 
         type = c("lower", "upper", "full")[3], #修改中括号内数值1~3选择不同类型的相关性矩阵
         cluster = T,  #是否进行聚类，默认值为False ，如果设置为T，那么就无法自定义顺序
         is.cor = F,  #输入的数据是否是相关性系数结果，默认为F，表示输入的是元素数据
         circular = F, #默认为F，表示是否转换为环形图，可设置为T
         grid.colour = "black", #网格颜色，默认为"grey50"
         grid.size = 0.25,  #网格线条粗细，默认0.25
         show.diag = T, #是否显示对角线
         cor.test = TRUE,
         method = "pearson") +

  #下面任选一个图形，其他的在代码最前面加#号，注意此处多了get_data(type = "lower")，可以设置"lower", "upper", "full"等
  geom_square(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2) +  #绘制正方形热图
  #geom_circle2(data = get_data(type = "lower"), colour = "grey35", size = 0.25, linetype = 2)+ #绘制圆形热图
  #geom_ellipse2(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2)+ #椭圆形热图
  #geom_colour(data = get_data(type = "lower"), colour = "#5a5c5f", size = 0.6, linetype = 2)+   #经典热图
  #geom_pie2(data = get_data(type = "lower"))+ #绘制饼图
  #geom_star(data = get_data(type = "lower"))+ #绘制五角星热图
  geom_shade(data = get_data(type = "lower"),sign = 1)+ #添加斜线阴影,sign>0,则在R值大于0的位置添加阴影。反之...
  geom_mark(data = get_data(type = "upper", r != 1, p.value < 0.05), #get_data调用dplyr包的filter函数用于过滤
            size = 2  #设置字体大小
            #aes(colour = r), #设置字体颜色映射
            #show.legend = F
  )+
  # geom_cross(data = get_data(type = "lower"), colour = "orange")+ #交叉标记，排除不显著的(即右上角空白处对应的位置)
  scale_fill_gradientn(colours = mycolors,  #自定义颜色
                       breaks = c(-1, 0, 1)) +  #自定义刻度值
  labs(fill = "Cor(R)")+ #修改图例标题
  theme(
    axis.text.x = element_text(color = c(rep(mycolors[1], 5), rep(mycolors[length(mycolors)-2], 6)), #X轴标签颜色
                               #face = "bold", 
                               size = 10), #设置加粗字体和大小
    axis.text.y = element_text(color = c(rep(mycolors[1], 6), rep(mycolors[length(mycolors)-2], 5)), #Y轴标签颜色
                               #face = "bold", 
                               size = 10)   #设置加粗字体和大小
  )

ggsave("salmon_cor.pdf", width = 4.4, height = 4) #保存
```

<img title="" src="file:///D:/software/MarkText/picture/2023-11-20-09-35-15-image.png" alt="" width="322"><img title="" src="file:///D:/software/MarkText/picture/2023-11-20-09-36-20-image.png" alt="" width="326">

```r
#师姐代码。先计算相关性矩阵cor,然后用pheatmap画相关性热图
mat.corr1 <- cor(runY_RSEM[inter,c('effective_length','expected_count','TPM','FPKM')])
setHook("grid.newpage", function() pushViewport(viewport(x=1,y=1,width=0.9, height=0.9, name="vp", just=c("right","top"))), action="prepend")
pheatmap(mat.corr1,cluster_cols = F,cluster_rows = F, main = "RSEM RNA-seq Quantification Correlation",cellheight=50, cellwidth = 50)
setHook("grid.newpage", NULL, "replace")
grid.text("RSEM", x=0.4,y=-0.07, gp=gpar(fontsize=13))
grid.text("RSEM", x=-0.001, rot=90, gp=gpar(fontsize=13))
```

**Please `knit` your homework to HTML file, and rename is as '03_Zhangsan_Homework1.html'. **
**Please submit your homework1 to http://140.210.214.122 before 23:59 of Jul/24/2021.**
